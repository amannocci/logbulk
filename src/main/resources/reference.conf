input {
  # file {
  #   chunk = 8192
  #   delimiter = "\n"
  #   path = "/path/to/file"
  #   dispatch = "app-route"
  #   worker = false
  # }

  # stdin {
  #   delimiter = "\n"
  #   dispatch = "app-route"
  #   worker = false
  # }

  # tcp {
  #   delimiter = "\n"
  #   host = "0.0.0.0"
  #   port = 8080
  #   dispatch = "app-route"
  #   worker = false
  # }

  # mysql {
  #   host = ""
  #   port = 3306
  #   maxPoolSize = 1
  #   username = ""
  #   password = ""
  #   database = ""
  #   charset = ""
  #   queryTimeout = ""
  #   parameters {
  #     id = 0
  #     limit = 1000
  #   }
  #   order = [
  #     "id",
  #     "limit"
  #   ]
  #   track = "id"
  # }

  # exec {
  #   command = ""
  #   interpreter = "/bin/sh"
  #   arguments = "-c"
  #   interval = 1
  #   dispatch = "app-route"
  #   worker = false
  # }

  # heartbeat {
  #   message = ""
  #   interval = 1
  #   dispatch = "app-route"
  #   worker = false
  # }
}

transform {
  # metric {
  #   mailbox = 1000
  #   instance = 1
  #   worker = false
  # }

  # anonymise {
  #   fields = []
  #   hashing = "md5"
  #   mailbox = 1000
  #   instance = 1
  #   worker = false
  # }

  # dispatch {
  #   dispatch = {
  #     "route" = {
  #       mode = "start"
  #       match = ""
  #     }
  #     "route-bis" = {}
  #   }
  #   mailbox = 1000
  #   instance = 1
  #   worker = false
  # }

  # csv {
  #   columns = {}
  #   source = ""
  #   separator = "\n"
  #   delimiter = ""
  #   mailbox = 1000
  #   instance = 1
  #   worker = false
  # }

  # grok {
  #   path = "/path/to/pattern"
  #   match = "message"
  #   format = "%{GREEDYDATA:message}"
  #   fallback = "fallback-route"
  #   mailbox = 1000
  #   instance = 1
  #   worker = false
  # }

  # json {
  #   source = ""
  #   mailbox = 1000
  #   instance = 1
  #   worker = false
  # }

  # mutate {
  #   remove = []
  #   rename = {}
  #   strip = []
  #   uppercase = []
  #   lowercase = []
  #   join = {}
  #   update = {}
  #   convert = {
  #     convertInt = "integer"
  #     convertFloat = "float"
  #     convertString = "string"
  #   }
  #   mailbox = 1000
  #   instance = 1
  #   worker = false
  # }

  # date {
  #   match = "date"
  #   format = "dd/MM/YYYY"
  #   meta = "YYYY.MM.dd"
  #   mailbox = 1000
  #   instance = 1
  #   worker = false
  # }
}

output {
  # file {
  #   chunk = 8192
  #   path = "data/output.log"
  #   delimiter = "\n"
  #   worker = false
  # }

  # stdout {
  #   pretty = false
  #   worker = false
  # }

  # elasticsearch {
  #   hosts = [
  #   ]
  #   bulk = 1000
  #   flush = 10
  #   type = "type"
  #   index = "index"
  #   queue = 100
  #   pool = 5
  #   worker = false
  # }

  # mongo {
  #   collection = ""
  #   database = ""
  #   uri = ""
  #   bulk = 1000
  #   flush = 10
  #   queue = 100
  # }
}

route {}

component {
  input {
    stdin = "io.techcode.logbulk.pipeline.input.StdInput"
    file = "io.techcode.logbulk.pipeline.input.FileInput"
    tcp = "io.techcode.logbulk.pipeline.input.TcpInput"
    exec = "io.techcode.logbulk.pipeline.input.ExecInput"
    heartbeat = "io.techcode.logbulk.pipeline.input.HeartbeatInput"
    mysql = "io.techcode.logbulk.pipeline.input.MysqlInput"
  }

  transform {
    dispatch = "io.techcode.logbulk.pipeline.transform.DispatchTransform"
    grok = "io.techcode.logbulk.pipeline.transform.GrokTransform"
    date = "io.techcode.logbulk.pipeline.transform.DateTransform"
    json = "io.techcode.logbulk.pipeline.transform.JsonTransform"
    mutate = "io.techcode.logbulk.pipeline.transform.MutateTransform"
    metric = "io.techcode.logbulk.pipeline.transform.MetricTransform"
    anonymise = "io.techcode.logbulk.pipeline.transform.AnonymiseTransform"
    csv = "io.techcode.logbulk.pipeline.transform.CsvTransform"
  }

  output {
    file = "io.techcode.logbulk.pipeline.output.FileOutput"
    stdout = "io.techcode.logbulk.pipeline.output.StdOutput"
    elasticsearch = "io.techcode.logbulk.pipeline.output.ElasticOutput"
    mongo = "io.techcode.logbulk.pipeline.output.MongoOutput"
  }
}